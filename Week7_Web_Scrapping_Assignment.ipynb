{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "544bdc57-da81-4416-8a49-c398a9c0c47c",
   "metadata": {},
   "source": [
    "# Week7 Web Scrapping Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e25926-0bc6-476c-ba02-cebfcb4bc543",
   "metadata": {},
   "source": [
    "### Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82c2df6-6e84-4552-a520-1142da8cec91",
   "metadata": {},
   "source": [
    "Web Scraping is the automated process of extracting information and data from websites. It can be done bt using software tools or scripts to access web pages, retrieve the desired content , and then organise or store that content for furthur analysis.It is used to gather data from websites in a structured manner, often for purposes such as data analysis, research and much more.\n",
    "\n",
    "Web Scraping is used for various reasons, including:\n",
    "\n",
    "+ Data Collection and Analysis:\n",
    "Web scraping allows businesses and researchers to collect large amounts of data from the web, which can then be analyzed to gain insights and make informed decisions.\n",
    "\n",
    "+ Research and Monitoring: \n",
    "Researchers often use web scraping to gather data for academic studies, market research, sentiment analysis, and other purposes.\n",
    "\n",
    "+ Machine Learning and AI Training:\n",
    "Web scraping is often used to collect data for training machine learning models and artificial intelligence systems. For instance, a company might scrape reviews from various websites to train a sentiment analysis model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922002e7-d2bf-43d4-ae4e-7107f3f658f7",
   "metadata": {},
   "source": [
    "### Q2. What are the different methods used for Web Scraping?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e37df2c-70aa-4773-b1e0-efecf9e4bed6",
   "metadata": {},
   "source": [
    "There are several methods used for web scraping : \n",
    "\n",
    "+ Manual Copy-Pasting : \n",
    "This is the simplest form of web scraping, where useds manually visit different websites and manually copy paste data from those pages into a spreadsheet or a text document. While this method is straightforward, its time-consuming and not practical for scraping huge amount of data.\n",
    "\n",
    "+ HTTP Requests and Libraries : \n",
    "Programming languages like Pyhton provide libraries like `requests` that allow you to send HTTP requests to web servers and retrieve HTML content. We can then parse the content using libraries liek `BeautifulSoup` to extract any info we want.\n",
    "\n",
    "+ Web Scraping Frameworks : \n",
    "There are specialised frameworks like Scrapy in Python that provide higher level approach to web scraping. These frameworks handles tasks like sending requests, parsing responses, making it more efficient for large scale scraping.      \n",
    "\n",
    "+ APIs : \n",
    "Some websites also offer APIs that allow developers to retrieve data in a structured format without needing to scrape HTML. APIs provide a more reliable and ethical way to access data when available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38611a5c-b2da-40ff-a142-c6c2801cf982",
   "metadata": {},
   "source": [
    "### Q3. What is Beautiful Soup? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca5063-b347-43ba-9872-32546b4b8cdd",
   "metadata": {},
   "source": [
    "A popular Python library for web scraping is called Beautiful Soup. It offers resources for exploring the structures of HTML and XML documents and extracting data from them. By enabling you to extract particular elements, attributes, and text, Beautiful Soup makes it simpler to work with HTML content that has been downloaded from websites.\n",
    "\n",
    "BeautifulSoup is used for various purposes like:\n",
    "+ Parsing HTML and XML : \n",
    "Beautiful Soup parses raw HTML or XML documents into a structured format that can be navigated and manipulated programmatically. IT creates a parse tree that represents the documents's structure , making it easier to locate and extract specific information.\n",
    "\n",
    "+ Navigation: \n",
    "Once the document is parsed, Beautiful Soup provides methods for navigating the parse tree. You can traverse the tree to access elements, their attributes, and their content. This navigation allows you to pinpoint the exact data you want to extract.\n",
    "\n",
    "+ Searching and Filtering: \n",
    "Beautiful Soup allows you to search for elements using various filters such as tag names, attributes, and text content. This is particularly useful for targeting specific data within a document, even when it's nested within complex structures.\n",
    "\n",
    "+ Robust Handling:\n",
    "HTML documents from the web can often be messy, with unclosed tags, inconsistent formatting, and other issues. Beautiful Soup is designed to handle such imperfect HTML gracefully, allowing you to work with a wide range of documents without major parsing errors.\n",
    "\n",
    "+ Readable and Maintainable Code: \n",
    "Beautiful Soup's intuitive syntax and methods make it easy to write readable and maintainable code for web scraping. This is especially valuable when dealing with complex HTML structures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd88f2-bd77-48a4-a1bf-de6eabbeb209",
   "metadata": {},
   "source": [
    "### Q4. Why is flask used in this Web Scraping project?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4ace2c-6b10-4838-9bc2-568cf3361869",
   "metadata": {},
   "source": [
    "Flask is a micro web framework for Python that is often used to build web applications and APIs.\n",
    "Flask is used in this Web Scraping project for various reasons like building user interface, data representation,and deployment\n",
    "\n",
    "+ Building User Interface : \n",
    "If we want that user interface should be able to interact with web scraping script , Flask can be used to build a web application that allows users to input parameters and view the results according to it.\n",
    "\n",
    "+ Data Representation : \n",
    "After scraping data, Flask can be used to present the results in a more organized and user-friendly format, such as generating HTML templates to display scraped data or charts or in the form of tables.\n",
    "\n",
    "+ Deployment : \n",
    "Flask applications can be easily deployed to various hosting platforms, such as Heroku, AWS, or DigitalOcean, allowing you to make your web scraping application accessible to users or other services.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6d948-3f53-465d-8601-6cb68e8e8ffb",
   "metadata": {},
   "source": [
    "### Q5. Write the names of AWS services used in this project. Also, explain the use of each service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e6a007-52e6-476e-bf75-5392e5f4803a",
   "metadata": {},
   "source": [
    "AWS services used in this project are Code Pipeline and Elastic Beanstalk.\n",
    "\n",
    "Code Pipeline connects to github code. First we upload code to github and then provide the github repository to code pipeline. so the github is connected to pipeline which furthur is connected to AWS Beanstalk.\n",
    "\n",
    "Elastic Beanstalk provides environment to deploy code and run it. It is basically a computer having RAM, memory and CPU to run and handle code. Code will be running in Beanstalk making the code global to run it from anywhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15a1f85-4347-4365-a900-632c9a6fbc07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
